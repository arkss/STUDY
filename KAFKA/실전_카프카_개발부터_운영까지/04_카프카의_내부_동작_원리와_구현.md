# 4.1 카프카 리플리케이션

고가용성 분산 스트리밍 플랫폼인 카프카는 무수히 많은 데이터 파이프라인의 정중앙에 위치하는 메인 허브 역할을 합니다. 따라서 카프카는 초기 설계 단계에서부터 이러한 일시적인 하드웨어 이슈 등으로 브로커 한 두 대에서 장애가 발생하더라도 중앙 데이터 허브로서 안정적인 서비스가 운영될 수 있도록 구상됐습니다. 이 때 안정성을 확보하기 위해 카프카 내부에서는 리플리케이션이라는 동작을 하게 됩니다. 



## 4.1.1 리플리케이션 동작 개요

카프카는 브로커의 장애에도 불구하고 연속적으로 안정적인 서비스를 제공함으로써 데이터 유실을 방지하며 유연성을 제공합니다. 카프카의 리플리케이션 동작을 위해 토픽 생성 시 필숫값으로 replication factor라는 옵션을 설정해야 합니다.

리플리케이션이 어떻게 동작하는지 살펴보기 위해 peter-kafka01에 접속합니다.

우선 peter-test01이라는 토픽을 생성합니다.

``` 
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 --create --topic peter-test01 --partitions 1 --replication-factor 3
```

```
Created topic peter-test01.
```



다음으로 토픽의 상세보기를 출력하겠습니다.

```
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic peter-test01 --describe
```

```
```

* 토픽의 파티션 수와 리플리케이션 팩터 수가 표시됩니다.
* 파티션0의 리더는 브로커 1을 나타냅니다.
* 리플리케이션들은 브로커1,2,3에 있습니다.
* Isr(In Sync Replica) : 현재 동기화되고 있는 리플리케이션들은 브로커1,2,3이라는 으미입니다. 
* 실제로 리플리케이션되는 것은 토픽이 아니라 토픽을 구성하는 각각의 파티션들입니다.



이제 메시지를 peter-test01 토픽으로 전송해보겠습니다. 

``` 
/usr/local/kafka/bin/kafka-cosole-producer.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic peter-test01
```



해당 메시지가 세그먼트 파일에 저장되어 있는지 살펴보겠습니다.

``` 
/usr/local/kafka/bin/kafka-dump-log.sh --print-data-log --files /data/kafka-logs/peter-test01-0/0000..0.log
```

```
```

* 시작 오프셋 위치는 0임을 알 수 있습니다.
* 메시지 카운트는 1임을 알 수 있습니다.
* 프로듀서를 통해 보낸 메시지는 test message1임을 알 수 있습니다.



현재 접속한 서버는 peter-kafka01이지만 카프카 클러스터를 이루는 다른 브로커들인 02,03에 접속해서 확인해도 동일한 메시지를 가지고 있습니다. 즉 N개의 리플리케이션이 있는 경우 N-1까지의 브로커 장애가 발생해도 메시지 손실 없이 안정적으로 메시지를 주고 받을 수 있습니다.



## 4.1.2 리더와 팔로워

모두 동일한 리플리케이션이라 하더라도 리더만의 역할이 따로 있기 때문에 카프카에서 리더를 특별히 강조해 표시합니다. 리더는 리플리케이션 중 하나가 선정되며 모든 읽기와 쓰기는 그 리더를 통해서만 가능합니다. 리더를 제외한 리플리케이션들은 리더에 문제가 발생하거나 이슈가 있을 경우를 대비해 언제든지 새로운 리더가 될 준비를 합니다. 컨슈머가 토픽의 메시지를 꺼내 가는 것과 비슷한 동작으로 지속적으로 파티션의 리더가 새로운 메시지를 받았는지 확인하고, 새로운 메시지가 있다면 해당 메시지를 리더로부터 복제합니다.



## 4.1.3 복제 유지와 커밋

리더와 팔로워는 ISR(InSyncReplica)라는 논리적 그룹으로 묶여 있습니다. 이렇게 리더와 팔로워를 별도의 그룹으로 나누는 이유는 기본적으로 해당 그룹 안에 속한 팔로워들만이 새로운 리더의 자격을 가질 수 있기 때문입니다. ISR 그룹에 속하지 않는 팔로워는 새로운 리더의 자격을 가질 수 없습니다.

ISR 내의 팔로워들은 리더와의 데이터 일치를 유지하기 위해 지속적으로 리더의 데이터를 따라가게 되고, 리더는 ISR 내 모든 팔로워가 메시지를 받을 때까지 기다립니다. 하지만 팔로워가  네트워크 오류, 브로커 장애 등 여러 이유로 리더로부터 리플리케이션하지 못하는 경우도 발생할 수 있습니다. 따라서 파티션의 리더는 팔로워들이 뒤쳐지지 않고 리플리케이션 동작을 잘하고 있는지를 감시합니다. 즉 리더에 뒤처지지 않고 잘 따라잡고 있는 팔로워들만이 ISR 그룹에 속하게 되며, 리더에 장애가 발생한 경우 새로운 리더의 자격을 얻을 수 있습니다.

리더는 읽고 쓰는 동작은 물론 팔로워가 리플리케이션 동작을 잘 수행하고 있는지도 판단합니다. 만약 팔로워가 특정 주기의 시간만큼 복제 요청을 하지 않는다면 리더는 해당 팔로워가 리플리케이션 동작에 문제가 발생했다고 판단해 ISR 그룹에서 추방합니다.

ISR 내에서 모든 팔로워의 복제가 완료되면, 리더는 내부적으로 커밋되었다는 표시를 하게 됩니다. 마지막 커밋 오프셋 위치는 하이워터마크라고 부릅니다. 즉 커밋되었다는 것은 리플리케이션 팩터 수의 모든 리플리케이션이 전부 메시지를 저장했음을 의미합니다. 그리고 이렇게 커밋된 메시지만 컨슈머가 읽어갈 수 있습니다. 

커밋된 메시지만 컨슈머가 읽어갈 수 있는 이유는 무엇일까요? 

* 커밋 전 컨슈머 A가 데이터를 읽어갑니다.
* 리더가 있는 브로커에 문제 발생하여 팔로워 중 하나가 새로운 리더가 됩니다. 새로운 리더는 컨슈머 A가 읽어간 데이터가 없습니다.
* 컨슈머 B가 새로운 리더로부터 데이터를 읽어갑니다.

이 결과, 컨슈머 A와 B는 동일한 토픽의 파티션을 읽었지만 다른 데이터를 읽어가게 됩니다.



결론적으로 커밋된 위치가 매우 중요합니다. 커밋된 위치를 어떻게 알 수 있을까요? 모든 브로커는 재시작될 때 커밋된 메시지를 유지하기 위해 로컬 디스크의 replication-offset-checkpoint라는 파일에 마지막 커밋 오프셋 위치를 저장합니다.

``` 
cat /data/kafka-logs/replication-offset-checkpoint
```

```
peter-test 0 1
// 토픽이름 파티션번호 커밋된오프셋번호
```



만약 특정 토픽 또는 파티션에 복제가 되지 않거나 문제가 있다고 판단되는 경우,  브로커들의replication-offset-checkpoint 정보를 확인하면 문제를 파악할 수 있습니다.



## 4.1.4 리더와 팔로워의 단계별 리플리케이션 동작

카프카로 향하는 수많은 메시지를 읽고 쓰기를 처리하는 리더는 매우 빠르게 동작을 합니다. 이렇게 바쁜 리더가 리플리케이션 동작을 위해 팔로워들과 많은 통신을 주고받거나 리플리케이션 동작에 많은 관여를 한다면 결과적으로 성능은 떨어지고 카프카의 장점인 빠른 성능을 내기도 어려울 것입니다. 따라서 카프카는 리더와 팔로워 간의 리플리케이션 동작을 처리할 때 서로의 통신을 최소화할 수 있도록 설계함으로써 리더의 부하를 줄였습니다. 

replication factor가 3으로 하나의 리더와 두 개의 팔로워가 있다고 생각합시다. 프로듀서가  토픽에 메시지를 전송하면 리더만 메시지를 저장하고 나머지 팔로워들은 아직 리더에게 저장된 메시지를 리플리케이션 하기 전입니다.

팔로워들은 리더에게 0번 오프셋 메시지 가져오기(fetch) 요청을 보낸 후 새로운 메시지가 있다는 사실을 인지하고 해당 메시지를 리플리케이션하려 합니다. 현재 리더는 모든 팔로워가 0번 오프셋 메시지를 리플리케이션하기 위한 요청을 보냈다는 사실을 알고 있습니다. 하지만 리더는 팔로워들이 동작을 성공했는지 실패했는지 여부를 알지 못합니다. 전통적인 메시징 큐 시스템인 래빗MQ의 트랜잭션 모드에서는 모든 미러(카프카에서의 팔로워)가 메시지를 받았는지에 대한 ACK를 리더에게 리턴하므로, 리더는 미러들이 메시지를 받았는지 알 수 있습니다. 하지만 카프카에의 경우에는 리더와 팔로워 사이에서 ACK를 주고받는 통신이 없습니다. 

카프카에서는 ACK를 주고받지 않으면서도 안정적으로 리플리케이션 동작을 할 수 있는지 알아봅시다. 프로듀서가 메시지를 보내면 리더는 1번 오프셋의 위치에 두 번째 새로운 메시지를 저장합니다. 0번 오프셋에 대한 리플리케이션 동작을 마친 팔로워들은 리더에게 1번 오프셋에 대한 리플리케이션을 요청합니다. 팔로워들로부터 1번 오프셋에 대한 리플리케이션 요청을 받은 리더는 팔로워들의 0번 오프셋에 대한 리플리케이션 동작이 성공했음을 인지하고, 오프셋 0에 대해 커밋 표시를 한 후 하이워터마크를 증가시킵니다.

팔로워가 0번 오프셋에 대한 리플리케이션을 성공하지 못했다면 팔로워는 1번 오프셋에 대한 리플리케이션 요청이 아닌 0번 오프셋에 대한 요청을 보내게 됩니다. 리더는 이를 통해 팔로워의 성공/실패 여부를 인지합니다.

팔로워들로부터 1번 오프셋 메시지에 대한 리플리케이션 요청을 받은 리더는 응답에 0번 오프셋 메시지가 커밋되었다는 내용도 함께 전달합니다. 

리더의 응답을 받은 팔로워들은 0번 오프셋 메시지가 커밋되었다는 사실을 인지하게 되고, 리더와 동일하게 커밋을 표시합니다.

카프카는 이렇게 ACK 통신을 제거했음에도 불구하고 팔로워와 리더 간의 리플리케이션 동작이 매우 빠르면서도 신뢰할 수 있다는 점입니다. 카프카에서 리더와 팔로워들의 리플리케이션 동작 방식은 리더가 푸시하는 방식이 아니라 팔로워들이 풀하는 방식으로 동작하는데 풀 방식을 채택한 이유도 리플리케이션 동작에서 리더의 부하를 줄여주기 위해서입니다.



## 4.1.5 리더에포크와 복구

리더에포크(LeaderEpoch)는 카프카의 파티션들이 복구 동작을 할 때 메시지의 일관성을 유지하기 위한 용도로 이용됩니다. 리더에포크는 컨트롤러에 의해 관리되는 32비트의 숫자로 표현됩니다. 해당 리더에포크 정보는 리플리케이션 프로토콜에 의해 전파되고, 새로운 리더가 변경된 후 변경된 리더에 대한 정보는 팔로워에게 전달됩니다. 리더에포크는 복구 동작 시 하이워터마크를 대체하는 수단으로도 활용됩니다.

### 리더에포크를 사용하지 않은 복구 과정

파티션 수 1, replication factor 2, min.insync.replicas는 1인 토픽을 예제로 진행합니다. 

1. 리더는 프로듀서로부터 메시지를 받았고 0번 오프셋에 저장, 팔로워는 리더에게 0번 오프셋에 대한 fetch 요청을 합니다.
2. fetch 요청을 통해 팔로워는 메시지를 리더로부터 리플리케이션합니다.
3. 리더는 하리워터마크를 1로 올립니다.
4. 리더는 프로듀서로부터 다음 메시지를 받은 뒤 1번 오프셋에 저장합니다.
5. 팔로워는 다음 메시지에 대해 리더에게 fetch 요청을 보내고 응답으로 리더의 하이워터마크 변화를 감지하고 자신의 하이워터마크도 1로 올립니다.
6. 팔로워는 1번 오프셋의 메시지를 리더로부터 리플리케이션합니다. 
7. 팔로워는 2번 오프셋에 대한 요청을 리더에게 보내고, 요청을 받은 리더는 하이워터마크를 2로 올립니다.
8. 팔로워는 2번 오프셋인 메시지까지 리플리케이션을 완료했지만 아직 리더로부터 하이워터마크를 2로 올리는 내용을 전달받지 못한 상태입니다.
9. 예상하지 못한 장애로 팔로워가 다운됩니다.
10. 팔로워가 장애에서 복구하면 자신의 워터마크보다 높은 메시지들은 신뢰할 수 없는 메시지로 판단하고 삭제합니다. 따라서 1번 오프셋 메시지는 삭제됩니다.
11. 팔로워는 리더에게 1번 오프셋에 fetch 요청을 보냅니다.
12. 이 순간 리더였던 브로커가 장애로 다운되면서 해당 파티션에 유일하게 남아있는 팔로워가 새로운 리더로 승격됩니다.
13. 새로운 리더는 1번 오프셋에 데이터가 없으므로 해당 데이터는 손실됩니다.       



### 리더에포크 활용

리더에포크를 활용하면 위 10번에서 차이가 있습니다. 기존에는 팔로워 장애 후 복구 시 자신의 하이워터마크보다 높은 메시지를 즉시 삭제했습니다. 하지만 리더에포크를 사용하는 경우에는 하이워터마크보다 큰 메시지를 무조건 삭제하는 것이 아니라 리더에게 리더에포크 요청을 보냅니다. 

1. 팔로워는 복구 동작을 하면서 리더에게 리더에포크 요청을 보냅니다.
2. 요청을 받은 리더는 리더에포크 응답으로 '1번 오프셋의 message2까지'라고 팔로워에게 보냅니다.
3. 팔로워는 자신의 하이워터마크보다 높은 1번 오프셋을 삭제하지 않고 하이워터마크를 상향 조정합니다.



리더에포크는 이렇게 복구 시 중요한 역할을 합니다. 리더에포크 요청과 응답에는 리더에포크 번호와 커밋된 오프셋 번호를 이용하는데 실습을 통해 이를 알아봅시다.

이름이 peter-test02, 파티션 수 1, replication factor 2인 토픽을 생성합니다.

``` 
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server perter-kafka01.foo.bar:9092 --create --topic peter-test02 --partitions 1 --replication-factor 2
```



토픽 상세보기 명령을 통해 현재 상태를 확인합니다. 브로커는 3개인데 replication factor는 2이므로 리플리케이션이 어느 브로커 2개에 생길 지, 실습할 때마다 결과가 다를 수 있습니다.

``` 
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic peter-test02 --decribe
```

```
```



이제 리더 브로커에 접속해 리더에포크 상태를 확인합니다.

``` 
cat /data/kafka-logs/peter-test02-0/leader-epoch-checkpoint
```

```
0
1 // 현재의 리더에포크 번호
0 0 // 리더에포크 번호, 최종 커밋 후 새로운 메시지를 받게 될 오프셋 번호 
```



파티션의 변화를 주기 위해 메시지를 전송합니다.

```
/usr/local/kafka/bin/kafka-console.producer.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic peter-test02
```



다시 리더에포크 상태를 확인해도 변화가 없습니다.

```
cat /data/kafka-logs/peter-test02-0/leader-epoch-checkpoint
```

```
0
1
0 0
```



리더에포크는 새로운 리더 선출이 발생하면 변경된 정보가 업데이트됩니다. 강제로 새로운 리더를 선출하도록 리더가 위치한 브로커1을 종료합니다.

```
sudo systemctl stop kafka-server
sudo systemctl status kafka-server
```



이제 팔로워가 리더로 선출되었을거라 생각하고 팔로워로 접속하여 리더에포크 상태를 확인합니다.

```
cat /data/kafka-logs/peter-test02-0/leader-epoch-checkpoint
```

```
0
2 // 현재의 리더에포크 번호, 리더에포크 번호는 리더가 변경될 때마다 하나씩 증가합니다.
0 0 // 리더에포크 번호가 1이었을 때를 기준으로 가장 마지막에 커밋된 후 새로 메시지를 받게 될 오프셋 번호를 기록합니다.
1 1 // 가장 마지막에 커밋된 오프셋 번호는 0이므로 카프카는 번호 1을 leader-epoch-checkpoint 파일에 기록하게 됩니다.
```



다운 됐던 구리더 브로커를 복구하면 leader-epoch-checkpoint 파일에 기록된 정보를 이용합니다. 구리더는 종료 직전 마지막 리더에포크 번호가 1이므로 뉴리더에게 1번 리더에포크에 대한 요청을 보내고, 뉴리더는 1번 리더에포크의 최종 커밋 후 준비된 오프셋 위치가 1이라는 응답을 보냅니다.



# 4.2 컨트롤러

이제 리더 선출을 맡고 있는 컨트롤러에 대해 알아봅시다. 카프카 클러스터 중 하나의 브로커가 컨트롤러 역할을 하게 되며, 파티션의 ISR 리스트 중에서 리더를 선출합니다. 컨트롤러는 브로커가 실패하는 것을 예의주시하고 있으며, 만약 브로커의 실패가 감지되면 즉시 ISR 리스트 중 하나를 새로운 파티션 리더로 선출합니다. 그러고 나서 새로운 리더의 정보를 주키퍼에 기록하고 변경된 정보를 모든 브로커에게 전달합니다. 파티션의 리더가 다운됐다면 클라이언트들은 모든 읽기/쓰기가 실패하고 재시도 숫자만큼 재시도를 하게 됩니다. 따라서 리더 선출 가정은 빠르게 이뤄져야 합니다.

아래 상황에서 리더가 선출되는 과정을 보겠습니다.

* 파티션 수 : 1
* 리플리케이션 팩터 수 : 2
* 브로커 배치 : 1,3번 브로커
* 현재 리더 위치 : 1번 브로커



### 예기치 않은 장애로 인한 리더 선출 과정

1. 파티션 0번의 리더가 있는 브로커 1번이 예기치 않게 다운됩니다.
2. 주키퍼는 1번 브로커와 연결이 끊어진 후, 0번 파티션의 ISR에서 변화가 생겼음을 감지합니다.
3. 컨트롤러는 주키퍼 위치를 통해 0번 파티션에 변화가 생긴 것을 감지하고 해당 파티션 ISR 중 3번을 새로운 리더로 선출합니다.
4. 컨트롤러는 0번 파티션의 새로운 리더가 3이라는 정보를 주키퍼에 기록합니다.
5. 이렇게 갱신된 정보는 현재 활성화 상태인 모든 브로커에게 전파됩니다.



### 관리자에 의해 이루어지는 안전한 종료 후 리더 선출 과정

1. 관리자가 브로커 종료 명령어를 실행하고, SIG_TERM 신호가 브로커에게 전달됩니다.

2. SIG_TERM 신호를 받은 브로커는 컨트롤러에게 알립니다.

3. 컨트롤러는 리더 선출 작업을 진행하고, 해당 정보를 주키퍼에 기록합니다.

4. 컨트롤러는 새로운 리더 정보를 다른 브로커들에게 전송합니다.

5. 컨트롤러는 종료 요청을 보낸 브로커에게 정상 종료한다는 응답을 보냅니다.

6. 응답을 받은 브로커는 캐시에 있는 내용을 디스크에 저장하고 종료합니다.



제어된 종료와 급작스러운 종료의 가장 큰 차이는 다운타임입니다. 제어된 종료를 사용하면 카프카 내부적으로 파티션들의 다운타임을 최소화할 수 있습니다. 그 이유는 브로커가 종료되기 전, 컨트롤러가 해당 브로커가 리더로 할당된 전체 파티션에 대해 리더 선출 작업을 진행하기 때문입니다. 그 뿐 아니라 제어된 종료의 경우 브로커는 자신의 모든 로그를 디스크에 동기화한 후 종료되므로 이후 다시 브로커가 재시작할 때 로그 복구 시간이 짧습니다. 다양한 장점이 있는 제어된 종료를 사용하려면 controlled.shutdown.enable = true 설정이 브로커의 설정 파일인 server.properties에 적용되어야 합니다.

아래 명령어로 브로커 설정을 확인할 수 있습니다.

```
/usr/local/kafka/bin/kafka-configs.sh --bootstrap-server peter-kafka01.foo.bar:9092 --broker 1 --describe --all
```



# 4.3 로그(로그 세그먼트)

카프카의 토픽으로 들어오는 메시지는 세그먼트(로그 세그먼트라고도 합니다.)라는 파일에 저장됩니다. 메시지는 정해진 형식에 맞추어 순차적으로 로그 세그먼트 파일에 저장됩니다. 로그 세그먼트에는 메시지의 내용만 저장되는 것이 아니라 메시지의 키, 벨류, 오프셋, 메시지 크기 같은 정보가 함께 저장되며, 로그 세그먼트 파일들은 브로커의 로컬 디스크에 보관됩니다. 

하나의 로그 세그먼트 크기가 너무 커져버리면 파일을 관리하기 어렵기 때문에, 로그 세그먼트의 최대 크기는 1GB가 기본값으로 설정되어 있습니다. 1GB보다 커지면 기본적으로 rolling 전략을 적용합니다. 하나의 로그 세그먼트에 메시지를 계속 덧붙이다가 1GB가 넘어가면 해당 파일은 클로즈하고, 새로운 로그 세그먼트를 생성하는 방식입니다.

로그 세그먼트 파일이 무한히 늘어날 경우를 대비해 로그 세그먼트에 대한 관리 계획을 수립해둬야 합니다. 관리 방법은 크게 로그 세그먼트 삭제와 컴팩션으로 구분할 수 있습니다.



## 4.3.1 로그 세그먼트 삭제

로그 세그먼트 삭제 옵션은 브로커의 설정 파일인 server.properties에서 log.cleanup.policy가 delete로 명시되어야 합니다. 이는 기본값입니다. 

로그 세그먼트 삭제 실습을 위해 토픽을 생성합니다.

``` 
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server perter-kafka01.foo.bar:9092 --create --topic peter-test03 --partitions 1 --replication-factor 3
```



콘솔 프로듀서를 이용해 log1 메시지를 전송합니다.

``` 
/usr/local/kafka/bin/kafka-console-producer.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic peter-test03
```

```
> log1
```



콘솔 컨슈머를 이용해 peter-test03 토픽의 메시지를 가져옵니다.

``` 
/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic peter-test03 --from-beginning
```

```
log1
```



이제 peter-test03 토픽에 retention.ms 옵션을 조정해서 메시지를 삭제해보겠습니다. 메시지 삭제 전 콘솔 프로듀서와 콘솔 컨슈머를 종료합니다.

```
/usr/local/kafka/bin/kafka-configs.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic peter-test03 --add-config retention.ms=0 --alter
```



설정한 내용은 아래와 같이 확인할 수 있습니다.

``` 
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic peter-test03 --describe
```

```
```



retention.ms은 해당 값보다 로그 세그먼트 보관 시간이 크면 세그먼트를 삭제한다는 명령어입니다. 보관 시간은 항상 0보다 크므로 삭제됩니다. 

로그 세그먼트의 삭제 작업은 5분(기본값) 주기로 삭제 작업을 수행합니다. 

삭제 전 로그 세그먼트 상태는 아래와 같습니다.

```
ls /data/kafka-logs/peter-test03-0/
```

```
```

* index : 로그 세그먼트에 저장된 위치와 오프셋 정보를 기록하는 파일
* log : 실제 메시지들이 저장되는 파일
* timeindex : 메시지의 타임스탬프를 기록하는 파일



5분 정도의 시간이 지난 후 다시 로그 세그먼트 상태를 확인하면 아래와 같습니다.

```
ls /data/kafka-logs/peter-test03-0/
```

``` 
```



위에서 확인했던 0으로 끝나는 파일은 삭제되고, 1로 끝나는 파일이 새로 생성됐습니다. 여기서 1은 오프셋을 의미하며 오프셋 시작 번호를 이용해 파일 이름을 생성하는 규칙을 따릅니다.

카프카의 관리자는 토픽마다 보관 주기를 조정해서. 얼마만큼의 기간 동안 카프카에 로그를 저장할지를 결정하고 관리할 수 있습니다. 관리자가 토픽에 별도의 retention.ms 옵션을 설정하지 않으면. 카프카의 server.properties에 적용된 옵션값이 적용됩니다. 카프카의 기본 설정값은 7일이므로, 모든 세그먼트 파일은 7일이 지남과 동시에 전부 삭제될 것입니다. 물론 기간이 지나지 않아도 retention.bytes라는 옵션을 이용해 지정된 크기를 기준으로도 로그 세그먼트를 삭제할 수 있습니다.



## 4.3.2 로그 세그먼트 컴팩션

컴팩션은 카프카에서 제공하는 로그 세그먼트 관리 정책 중 하나로 로그를 삭제하지 않고 컴팩션하여 보관할 수 있습니다. 로그 컴팩션은 기본적으로 로컬 디스크에 저장되어 있는 세그먼트를 대상으로 실행되는데, 현재 활성화된 세그먼트는 제외하고 나머지 세그먼트들을 대상으로 컴팩션이 실행됩니다.

컴팩션할지라도 무기한 보관한다면 용량의 한계에 도달할 것입니다. 따라서 카프카에서는 단순하게 메시지를 컴색션하여 보관하기보다는 좀 더 효율적인 방법으로 컴팩션합니다. 카프카에서 로그 세그먼트를 컴팩션하면 메시지의 키값을 기준으로 마지막 데이터만 보관하게 됩니다.

메시지의 키값을 기준으로 컴팩션하는 방법이 다소 생소할 수 있는데 로그 컴팩션 기능을 이용하는 대표적인 예제는 바로 카프카의 __consumer_offset 토픽입니다. 이는 카프카의 내부 토픽으로, 컨슈머 그룹의 정보를 저장하는 토픽입니다. 해당 토픽에 키(컨슈머 그룹명, 토픽명)와 밸류(오프셋 커밋 정보) 형태로 메시지가 저장됩니다.

예를 들어 CG01 컨슈머 그룹이 T01 토픽을 컨슘하고, 첫 번째 메시지를 읽고 커밋했다고 가정하겠습니다. 이 정보는 키와 밸류 형태의 형태로 __consumer_offset 토픽에 저장되어야 합니다. 따라서 키는 CG01, T01이고 벨류는 1(오프셋)인 메시지가 저장됩니다. 해당 키에 벨류가 계속 쌓이면 오프셋은 계속 늘어가서 1,2 ... n까지 저장됩니다. 그 상태에서 로그 컴팩션 동작이 일어나면 마지막 데이터인 n만 남게 됩니다. 컨슈머 그룹은 항상 마지막으로 커밋된 오프셋 정보가 중요하므로 과거에 커밋된 정보들은 삭제돼도 무방합니다.

이렇게 로그 컴팩션은 메시지의 키값을 기준으로 과거 정보는 중요하지 않고 가장 마지막 값이 필요한 경우에 사용합니다. 현재의 구매 현황 상태를 보여주는 시스템에서도 로그 컴팩션을 이용할 수 있습니다. 사용자 아이디를 키, 혙재의 구매 상태 정보를 벨류로 한다면 구매한 사용자 아이디를 기준으로 최종 상태만 노출하면 되므로 로그 컴팩션 기능이 적절합니다.

프로듀서가 카프카에 메시지를 전송할 때, 벨류는 필수값이지만 키는 필숫값이 아닙니다. 따라서 로그 컴팩션 기능을 사용하고자 한다면, 카프카로 메시지를 전송할 때 키도 필숫값으로 전송해야 합니다.

로그 컴팩션의 장점은 무엇일까요? 로그 컴팩션의 장점은 바로 빠른 장애 복구입니다. 장애 복구 시 전체 로그를 복구하지 않고, 메시지의 키를 기준으로 최신의 상태만 복구합니다. 따라서 전체 로그를 복구할 때보다 복구 시간을 줄일 수 있다는 장점이 있습니다.

카프카에서 로그 컴팩션 작업이 실행되는 동안 브로커의 과도한 입출력 부하가 발생할 수 있으니 유의해야 합니다. 따라서 반드시 브로커의 리소스 모니터링도 병행하여 로그 컴팩션을 사용하기를 권장합니다.



### 로그 컴팩션 관련 옵션

| 옵션 이름                         | 옵션값             | 적용 범위                 | 설명                                                         |
| --------------------------------- | ------------------ | ------------------------- | ------------------------------------------------------------ |
| cleanup.policy                    | compact            | 토픽의 옵션으로 적용      | 토픽 레벨에서 로그 컴팩션을 설정할 때 적용하는 옵션입니다.   |
| log.cleanup.policy                | compact            | 브로커의 설정 파일에 적용 | 브로커 레벨에서 로그 컴팩션을 설정할 때 적용하는 옵션입니다. |
| log.cleaner.min.compaction.lag.ms | 0                  | 브로커의 설정 파일에 적용 | 메시지가 기록된 후 컴팩션하기 전 경과되어야 할 최소 시간을 지정합니다. |
| log.cleaner.max.compaction.lag.ms | 922337036854775807 | 브로커의 설정 파일에 적용 | 메시지가 기록된 후 컴팩션하기 전 경과되어야 할 최대 시간을 지정합니다. |
| log.cleaner.min.cleanable.ratio   | 0.5                | 브로커의 설정 파일에 적용 | 로그에서 압축이 되지 않은 부분을 더티라고 표현합니다. 전체 로그 대비 더티의 비율이 50%가 넘으면 로그 컴팩션이 실행됩니다. |
