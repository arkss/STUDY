# 5.1 파티셔너

카프카의 토픽은 성능 향상을 위한 병렬 처리가 가능하도록 하기 위해 파티션으로 나뉩니다. 따라서 프로듀서는 토픽으로 메시지를 보낼 때 해당 토픽의 어느 파티션으로 메시지를 보내야 할지를 결정해야 하는데 이 때 사용하는 것이 파티셔너입니다. 프로듀서가 파티션을 결정하는 알고리즘은 기본적으로 메시지의 키를 해시 처리하기 때문에 키값이 동일하면 모두 같은 파티션으로 전송됩니다.

카프카는 클라이언트의 처리량을 높이기 위해 토픽의 파티션을 늘릴 수 있는 기능을 제공합니다. 이 때 파티션 수가 변경됨과 동시에 메시지의 키와 매핑된 해시 테이블도 변경됩니다.

이렇게 메시지의 키를 이용해 카프카로 메시지를 전송하는 경우, 관리자의 의도와는 다른 방식으로 메시지 전송이 이뤄질 수 있으므로 되도록 파티션 수를 변경하지 않는 것을 권장합니다.



## 5.1.1 라운드 로빈 전략

메시지의 키값은 필수가 아니기 때문에 키값을 지정하지 않으면 null로 전송됩니다. 이 때 기본값은 라운드 로빈 알고리즘을 사용해 프로듀서는 목적지 토픽의 파티션들로 레코드들을 랜덤 전송합니다.

파티셔너를 거친 후의 레코드들은 배치 처리를 위해 프로듀서의 버퍼 메모리 영역에서 잠시 대기한 후 카프카로 전송됩니다. 배치 처리를 위해 잠시 메시지들이 대기하는 과정에서 라운드 로빈 전략은 효율을 떨어뜨릴 수 있습니다. 

3개의 파티션이 있고 각 파티션 별로 배치 전송을 위해 필요한 레코드 수는 3이라고 가정합니다. 그러면 6개의 메시지가 들어와도 각 파티션에 2개씩 쌓이기 때문에 배치 전송은 일어나지 않습니다. 

물론 프로듀서의 옵션을 조정하여 특정 시간을 초과하면 즉시 전송하도록 설정할 수 있지만 배치와 압축의 효과를 얻지 못한 체 소수의 레코드만 카프카로 전송되는 것은 비효율적입니다.



## 5.1.2 스티키 파티셔닝 전략

라운드 로빈 전략에서 지연시간이 불필요하게 증가되는 비효율적인 전송을 개선하고자 2019년 카프카 2.4 버전부터는 스티키 파티셔닝 전략을 사용하게 됩니다. 스티키 파티셔닝이란 하나의 파티션에 레코드 수를 먼저 채워서 카프카로 빠르게 배치 전송하는 전략을 말합니다.

3개의 파티션이 있고 각 파티션 별로 배치 전송을 위해 필요한 레코드 수는 3이라고 가정합니다.  3개의 메시지만 들어오더라도 하나의 파티션에 보냄으로써 바로 배치 전송이 일어나게 합니다.

미묘한 변화라 생각할 수 있지만 스티키 파티셔닝 전략을 적용함으로써 기본 설정에 비해 약 30% 이상 지연시간을 감소하고 프로듀서의 CPU 사용률도 줄어드는 효과를 얻을 수 있었습니다. 카프카로 전송하는 메시지의 순서가 그다지 중요하지 않은 경우라면 스티키 파티셔닝 전략을 적용하기를 권장합니다.



# 5.2 프로듀서의 배치

프로듀서에서 처리량을 높이기 위해 배치 전송을 권장합니다. 배치 전송을 위해 토픽의 파티션별로 레코드들을 잠시 보관하고 있습니다.

프로듀서는 배치 전송을 위해 다음과 같은 옵션들을 제공합니다.

* buffer.memory : 카프카로 메시지들을 전송하기 위해 담아두는 프로듀서의 버퍼 메모리 옵션입니다. 기본 값은 32MB입니다.
* batch.size : 배치 전송을 위해 메시지들을 묶는 단위를 설정하는 배치 크기 옵션입니다. 기본값은 16KB입니다.
* linger.ms : 배치 전송을 위해 버퍼 메모리에서 대기하는 메시지들의 최대 대기시간을 설정하는 옵션입니다. 단위는 ms이며 기본값은 0입니다. 즉 기본값으로는 배치 전송을 위해 기다리지 않고 메시지들이 즉시 전송됩니다.

배치 전송 방식은 불필요한 I/O를 줄일 수 있어 매우 효율적이며 카프카의 요청 수도 줄여주는 효과도 있습니다.  하지만 무조건 배치 처리만 해야 하는 것은 아니며, 처리량을 높일지, 아니면 지연 없는 전송을 해야 할지 선택을 해야 합니다.



# 5.3 중복 없는 전송

카프카는 사용자들의 개발 편의를 높이기 위해 중복 없이 전송할 수 있는 기능을 제공합니다. 

메시지 시스템들의 메시지 전송 방식에는 적어도 한 번 전송(at-least-once), 최대 한 번 전송(at-most-once), 정확히 한 번 전송(exactly-once)이 있으며 적어도 한 번 전송과 최대 한 번 전송 방식은 서로 어떠한 차이가 있는지를 살펴봅시다.



### 적어도 한 번 전송

프로듀서 입장에서는 브로커가 메시지를 저장하고 ACK만 전송하지 못한 것인지, 메시지를 저장하지 못해서 ACK를 전송하지 않은 것인지는 정확히 알 수 없습니다.

하지만 메시지에 대한 ACK를 받지 못한 프로듀서는 적어도 한 번 전송 방식에 따라 메시지를 다시 한 번 전송합니다. 브로커가 메시지를 저장하고 ACK만 전송하지 못한 것이라면 처음으로 메시지를 저장할 것이고, 메시지를 저장하고 ACK만 전송하지 않은 것이라면 메시지를 중복 저장할 것입니다.

카프카는 기본적으로 이와 같은 적어도 한 번 전송 방식을 기반으로 동작합니다.



### 최대 한 번 전송

최대 한 번 전송은 ACK를 받지 못하더라도 재전송을 하지 않습니다.

최대 한 번 전송은 일부 메시지가 손실되더라도 높은 처리량을 필요로 하는 대량의 로그 수집이나 IoT 같은 환경에서 사용하곤 합니다.



### 중복 없는 전송

프로듀서가 브로커에게 메시지를 전송할 때 헤더에 PID(Producer ID)와 메시지 번호를 함께 전송합니다. 브로커는 메시지를 받고 PID와 메시지 번호를 메모리에 기록합니다. 이후 메시지를 받았을 때 해당 두 값을 비교하여 메시지를 저장할 지 판단합니다. 

PID는 사용자가 별도로 생성하는 것이 아니며 프로듀서에 의해 자동 생성됩니다. 또한 이 PID는 프로듀서와 카프카 사이에서 내부적으로만 이용되므로 사용자에게 따로 노출되지 않습니다. 또한 메시지마다 부여되는 시퀀스 번호는 0번부터 시작해 순차적으로 증가합니다. PID와 메시지 번호는 메모리에서 유지되고, 리플리케이션 로그에도 저장되기 때문에 브로커의 장애가 발생해도 중복없는 메시지 전송이 가능합니다.

중복 없는 전송 방식은 중복을 피하기 위한 오버헤드가 존재할 수 밖에 없습니다. 하지만 카프카에서는 메시지 비교 동작으로 발생하는 오버헤드를 최소화히기 위해 메시지에 단순한 숫자 필드만 추가하는 방법으로 구현했기에 오버헤드가 생각보다 높은 편이 아닙니다. 기존 대비 최대 20% 정도만 성능이 감소합니다.

중복 없는 전송을 하기 위해서는 아래와 같은 설정이 필요합니다.

| 프로듀서 옵션                         | 값   | 설명                                                         |
| ------------------------------------- | ---- | ------------------------------------------------------------ |
| enable.idempotence                    | true | 프로듀서가 중복 없는 전송을 허용할지 결정하는 옵션입니다. 해당 값을 true로 바꾼 후 아래 값들을 바꾸지 않으면 ConfigException이 발생합니다. |
| max.in.flight.requests.per.connection | 1~5  | ACK를 받지 않은 상태에서 하나의 커넥션으로 보낼 수 있는 최대 요청 수 입니다. 기본값은 5이며 5이하로 설정해야 합니다. |
| acks                                  | all  | 기본값은 1이며 all로 설정해야합니다.                         |
| retries                               | 5    | ACK를 받지 못할 경우 재시도를 해야하므로 0보다 큰 값으로 설정해야 합니다. |



### 중복 없는 전송 실습

아래 명령어로 토픽을 생성합니다.

```
```



다음으로는 프로듀서 설정 파일을 생성합니다.

``` 
vi /home/ec2-user/producer.config
```

```
enable.idempotence=true
max.in.flight.requests.per.connection=5
acks=all
retries=5
```



콘솔 프로듀서를 위에서 만든 설정 파일을 통해 실행합니다.

```
/usr/local/kafka/bin/kafka-console-producer.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic peter-test04 --producer.config /home/ec2-user/producer.config
```

```
> exactly once1
```



아래 경로의 snapshot 파일을 확인합니다. snapshot 파일은 브로커가 PID와 시퀀스 번호를 주기적으로 저장하는 파일입니다.

```
cd /data/kafka-logs/peter-test04-0/
```



카프카의 dump 명령어를 이용해 snapshot 파일을 확인해보겠습니다.

```
/usr/local/kafka/bin/kafka-dump-log.sh --print-data-log --files /data/kafka-logs/peter-test04-0/00000...1.snapshot
```

```
```



# 5.4 정확히 한 번 전송

실제로 애플리케이션에서 정확히 한 번 처리를 구현하기는 굉장히 어렵습니다.

앞서 카프카에서는 멱등성 옵션을 이용해 중복 없는 전송을 할 수 있다고 설명했습니다. 하지만 이 중복 없는 전송 방식이 정확히 한 번 전송한다는 의미는 아닙니다. 카프카에서 정확히 한 번 전송은 트랜잭션과 같은 전체적인 프로세스 처리를 의미하며, 중복 없는 전송은 정확히 한 번 전송의 일부 기능이라 할 수 있습니다.

전체적인 프로세스를 관리하기 위해 카프카에서는 정확히 한 번 처리를 담당하는 별도의 프로세스가 있는데 이를 트랜잭션 API라고 부릅니다. 				



## 5.4.1 디자인

프로듀서가 카프카로 정확히 한 번 방식으로 메시지를 전송할 때 프로듀서가 보내는 메시지들은 원자적으로 처리되어 전송에 성공하거나 실패하게 됩니다. 이런 프로듀서의 전송을 위해 카프카에서는 컨슈머 그룹 코디네이터와 동일한 개념으로 트랜잭션 코디네이터라는 것이 서버 측에 존재합니다. 이 트랜잭션 코디네이터의 역할은 프로듀서에 의해 전송된 메시지를 관리하며, 커밋 또는 중단 등을 표시합니다. 카프카에서는 컨슈머 오프셋 관리를 위해 오프셋 정보를 카프카의 내부 토픽에 저장하는데, 트랜잭션도 동일하게 트랜잭션 로그를 카프카의 내부 토픽인 `__transaction_state`에 저장합니다. `__transaction_state`는 카프카의 내부 토픽이지만 이 역시 토픽이므로 파티션 수와 리플리케이션 팩터가 존재하며, 브로커의 설정을 통해 관리자가 설정할 수 있습니다. 기본값은 아래와 같습니다.

* transaction.state.log.num.partitions=50
* transaction.state.log.replication.factor=3

이 때 프로듀서가 해당 토픽에 트랜잭션 로그를 직접 기록하는 것이 아니라 프로듀서는 트랜잭션 코디네이터에게 알리고 트랜잭션 코디네이터가 직접 기록합니다.

정확히 한 번 전송을 이용해 전송된 메시지들이 카프카에 저장되면, 카프카의 메시지를 다루는 클라이언트들은 해당 메시지들이 정상적으로 커밋된 것인지 또는 실패한 것인지 식별할 수 있어야 합니다. 카프카에서는 이를 식별하기 위한 정보로서, 컨트롤 메시지라고 불리는 특별한 타입의 메시지가 추가로 사용됩니다.

컨트롤 메시지는 페이로드에 애플리케이션 데이터를 포함하지 않으며, 애플리케이션들에게 노출되지 않습니다. 컨트롤 메시지는 오직 브로커와 클라이언트 통신에서만 사용됩니다.



## 프로듀서 예제 코드

정확히 한 번 전송을 위해 프로듀서에 필수로 설정해야 하는 옵션들이 있습니다.

```java
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class ExactlyOnceProducer {
    public static void main(String[] args) {
        String bootstrapServers = "peter-kafka01.foo.bar:9092";
        Properties props = new Properties();
        props.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.setProperty(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.setProperty(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.setProperty(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "true"); // 정확히 한번 전송을 위한 설정
        props.setProperty(ProducerConfig.ACKS_CONFIG, "all"); // 정확히 한번 전송을 위한 설정
        props.setProperty(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, "5"); // 정확히 한번 전송을 위한 설정
        props.setProperty(ProducerConfig.RETRIES_CONFIG, "5"); // 정확히 한번 전송을 위한 설정
        props.setProperty(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "peter-transaction-01"); // 정확히 한번 전송을 위한 설정

        Producer<String, String> producer = new KafkaProducer<>(props);

        producer.initTransactions(); // 프로듀서 트랜잭션 초기화
        producer.beginTransaction(); // 프로듀서 트랜잭션 시작
        try {
            for (int i = 0; i < 1; i++) {
                ProducerRecord<String, String> record = new ProducerRecord<>("peter-test05", "Apache Kafka is a distributed streaming platform - " + i);
                producer.send(record);
                producer.flush();
                System.out.println("Message sent successfully");
            }
        } catch (Exception e){
            producer.abortTransaction(); // 프로듀서 트랜잭션 중단
            e.printStackTrace();
        } finally {
            producer.commitTransaction(); // 프로듀서 트랜잭션 커밋
            producer.close();
        }
    }
}
```



중복 없는 전송과 정확히 한 번 전송의 옵션 설정에서 가장 큰 차이점이자 주의해야 할 설정은 `TRANSACTIONAL_ID_CONFIG` 입니다. 프로듀서의 `TRANSACTIONAL_ID_CONFIG` 옵션은 실행하는 프로듀서 프로세스마다 고유한 아이디로 설정해야 합니다. 2개의 프로듀서가 있다면 두 프로듀서마다 다른 아이디로 설정해야 합니다. 



## 5.4.3 단계별 동작

### 트랜잭션 코디네이터 찾기

정확히 한 번 전송을 위해서는 트랜잭션 API를 이용한다고 설명했습니다. 따라서 가장 먼저 수행하는 작업은 트랜잭션 코디네이터 찾기입니다. 프로듀서는 브로커에게 FindCoordinatorRequest를 보내서 트랜잭션 코디네이터의 위치를 찾습니다. 트랜잭션 코디네이터는 브로커에 위치하여 PID(Producer ID)와 transaction.id를 매핑하고 해당 트랜잭션 전체를 관리합니다.

`__transaction_state` 토픽의 파티션 번호는 transactional.id를 기반으로 해시하여 결정되고, 이 파티션의 리더가 있는 브로커가 트랜잭션 코디네이터의 브로커로 최종 선정됩니다. 



### 프로듀서 초기화

프로듀서는 initTransactions() 메소드를 이용해 트랜잭션 전송을 위한 InitPidRequest를 트랜잭션 코디네이터로 보냅니다. 이 때 TID가 설정된 경우에는 InitPidRequest와 함께 TID가 트랜잭션 코디네이터에게 전송됩니다. 트랜잭션 코디네이터는 TID, PID를 매핑하고 해당 정보를 트랜잭션 로그에 기록합니다. 그런 다음 PID 에포크를 한 단계 올리는 동작을 하게 되고, PID 에포크가 올라감에 따라 이전의 동일한 PID와 이전 에포크에 대한 쓰기 요청은 무시됩니다. 에포크를 활용하는 이유는 신뢰성 있는 메시지 전송을 하기 위함입니다.



### 트랜잭션 시작

프로듀서는 beginTransaction() 메소드를 이용해 새로운 트랜잭션의 시작을 알리게 됩니다. 프로듀서는 내부적으로 트랜잭션이 시작됐음을 기록하지만 트랜잭션 코디네이터 관점에서는 첫 번째 레코드가 전송될 때까지 트랜잭션이 시작된 것은 아닙니다.



### 트랜잭션 상태 추가

프로듀서는 토픽 파티션 정보를 트랜잭션 코디네이터에게 전달하고 트랜잭션 코디네이터는 해당 정보를 트랜잭션 로그에 기록합니다. TID와 파티션의 정보가 트랜잭션 로그에 기록되며 트랜잭션의 현재 상태를 Ongoing으로 표시합니다. 만약 트랜잭션 로그에 추가되는 첫 번째 파티션이라면 트랜잭션 코디네이터는 해당 트랜잭션에 대한 타이머를 시작합니다. 기본값으로 1분 동안 트랜잭션 상태에 대한 업데이트가 없다면, 해당 트랜잭션은 실패로 처리됩니다.



### 메시지 전송

프로듀서는 대상 토픽의 파티션으로 메시지를 전송합니다. 해당 메시지에는 PID, 에포크, 시퀀스 번호가 함께 포함되어 전송됩니다. 트랜잭션 코디네이터가 있는 브로커와 프로듀서가 전송하는 메시지를 받는 브로커가 서로 다를 수 있습니다.



### 트랜잭션 종료 요청

메시지 전송을 완료한 프로듀서는 commit Transaction() 메소드 또는 abortTransaction() 메소드 중 하나를 반드시 호출해야 하며, 해당 메소드의 호출을 통해 트랜잭션이 완료됨을 트랜잭션 코디네이터에게 알립니다. 트랜잭션 코디네이터는 두 단계의 커밋 과정을 시작하게 되며, 첫 번째 단계로 트랜잭션 로그에 해당 트랜잭션에 대한 PrepareCommit 또는 PrepareAbort를 기록합니다.



### 사용자 토픽에 표시

트랜잭션 코디네이터는 두 번째 단계로서 트랜잭션 로그에 기록된 토픽의 파티션에 트랜잭션 커밋 표시를 기록합니다. 여기서 기록하는 메시지가 바로 컨트롤 메시지입니다. 

예를 들어 트랜잭션 프로듀서가 파티션0에 메시지를 전송했고 해당 메시지의 오프셋이 1이라고 가정해봅시다. 트랜잭션 코디네이터는 파티션0에 트랜잭션 커밋 표시 메시지를 기록하고, 이 추가 메시지(컨트롤 메시지)로 인해 파티션0의 마지막 오프셋은 2로 증가합니다. 이 메시지는 해당 PID의 메시지가 제대로 전송됐는지 여부를 컨슈머에게 나타내는 용도로도 사용됩니다. 따라서 트랜잭션이 커밋이 끝나지 않은 메시지는 컨슈머에게 반환하지 않으며, 오프셋의 순서 보장을 위해 트랜잭션 성공 또는 실패를 나타내는 LSO라는 오프셋을 유지하게 됩니다. 



### 트랜잭션 완료

트랜잭션 코디네이터는 완료됨(Committed)이라고 트랜잭션 로그에 기록합니다. 그리고 프로듀서에게 해당 프랜잭션이 완료됨을 알린 다음 해당 트랜잭션에 대한 처리는 모두 마무리됩니다. 트랜잭션을 이용하는 컨슈머는 read_committed 설정을 하면 트랜잭션에 성공한 메시지들만 읽을 수 있게 됩니다.



## 5.4.4 예제 실습

정확히 한 번 전송 예제를 실습해봅시다. 실습을 위해 peter-test05라는 토픽을 생성합시다. 파티션 수는 1, 리플리케이션 팩터 수는 3입니다.

```
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 --create --topic peter-test05 --partitions 1 --replication-factor 3
```



일반 콘솔 프로듀서가 아닌 트랜잭션 프로듀서 자바 코드를 이용해 메시지를 전송하겠습니다. 

배포 서버은 peter-ansible에서 실습을 진행합니다.

```
sudo yum install -y java-1.8.0-openjdk java-1.8.0-openjdk-devel
```



자바 버전을 확인합니다.

```
java -version
```

```
```



이제 JAR 파일이 위치한 경로 이동해 실제로 실행해보겠습니다.

```
cd kafka2/chapter5/
java -jar ExactlyOnceProducer.jar
```



이제 브로커에 접근하기 위해 peter-kakfka01 서버로 접근한 후 다음 명령어를 이용해 카프카의 전체 토픽 리스트를 확인해보겠습니다.

````
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 --list
```

```
```



토픽 리스트 중 예전에는 확인할 수 없었던 `__transaction_state` 라는 토픽이 생겼습니다. 이는 트랜잭션 로그를 기록하는 카프카의 내부 토픽입니다. 

콘솔 컨슈머로 해당 토픽의 내용을 읽기 위해서는 컨슈머 옵션을 하나 추가해야 합니다.

```
vi /home/ec2-user/consumer.config
```

```
exclude.internal.topics=false
```



consumer.config 파일을 작성했으면 다음 명령어를 이용해 `__transaction_state` 토픽의 내용을 읽어보겠습니다.

```
/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic __transaction_state --consumer.config /home/ec2-user/consumer.config --formatter "kafka.coordinator.transaction.TransactionLog\$TransactionLogMessageFormatter" --from-beginning
```

```
```



이번에는 peter-test05 토픽의 로그 파일을 한 번 살펴보겠습니다.

```
/usr/local/kafka/bin/kafka-dump-log.sh --print-data-log --files /data/kafka-logs/peter-test05-0/00000000000000000000.log
```

```
```

분명히 트랜잭션 프로듀서를 이용해 하나의 메시지만 전송했는데 세그먼트 파일을 확인해보니 오프셋0과 오프셋1이 기록되어 있습니다. 일반적인 경우라면 0번 오프셋만 기록되어 있어야 합니다. 추가된 1번 오프셋 부분이 바로 앞서 설명한 정확히 한 번 단계별 동작 중 사용자 토픽에 트랜잭션 완료 유무 표시와 관련된 내용입니다. 



































