# 1.1 잘란도와 트위터의 카프카 도입 사례

## 1.1.1 유럽 최대 온라인 패션몰 잘란도의 도전 사례

유럽 최대의 패션플랫폼 잘란도는 active user 3,100만명, 연간 주문 수는 1억 4,500만건, 상품 판매 건수는 50만건을 기록하고 있습니다.

데이터의 변화가 스트림으로 컨슈머 측에 전달되는 이벤트 드리븐 시스템으로의 전환을 결정했습니다. 이벤트 드리븐 시스템 도입을 통해 데이터를 소비하는 컨슈머들은 자신의 요구사항에 따라 데이터를 처리하거나 구독할 수 있게 됐습니다.



### 위기에 봉착한 잘란도

이벤트 드리븐 시스템 구성에서 가장 중요한 사항은 바로 인바운드 데이터와 아웃바운드 데이터가 동일해야 한다는 점입니다. 사내의 여러 부서에서 데이터를 소비하는데, 이 때 서로 소비한 데이터 불일치하거나 일부 데이터가 누락된다면 데이터에 대한 신뢰성을 잃게 되고 결국 쓸모없는 데이터로 취급받게 됩니다.

초기에는 데이터의 오차를 줄이려는 목적으로 API와 posetgreSQL로 연결하는 CRUD 타입으로 구성하고, 데이터베이스 업데이트가 완료된 후에는 아웃바운드 이벤트가 생성되도록 구성했습니다. 이를 통해 데이터의 오차는 줄일 수 있었지만 동기화 방식에서 다음과 같은 한계점이 문제로 불거졌습니다.

* 여러 네트워크를 이용하는 환경에서 모든 데이터 변경에 대한 올바른 전달 보장 문제
* 동일한 데이터를 동시에 수정하면서 정확하게 순서를 보장해야 하는 문제, 그리고 수정된 이벤트들을 정확한 순서대로 아웃바운드 전송하는 문제
* 다양한 클라이언트들의 요구사항을 효율적으로 지원하기 어려운 문제
* 빠른 전송을 위한 클라이언트 또는 대량의 배치 전송을 위한 클라이언트를 지원하기 어려운 문제



### 비동기 방식의 대표 스트리밍 플랫폼, 카프카 도입

카프카를 도입한 이유는 아래와 같습니다.

* 높은 처리량
* 순서 보장
* at least once 전송 방식
* 강력한 파티셔닝
* 자연스러운 백프레셔 핸들링
* 로그 컴팩션



#### 빠른 데이터 수집이 가능한 높은 처리량

HTTP 기반으로 전달되는 이벤트일지라도 이벤트가 카프카로 처리되는 응답시간은 불과 한 자릿수의 밀리초 단위로 처리되었습니다. 빠르고 안전한 데이터 전송이 가능해지자 더 광범위한 데이터 흐름을 만들 수 있게 됐습니다.



#### 순서 보장

이벤트 처리 순서가 보장되면서, 엔티티 간의 유효성 검사나 동시 수정같은 무수한 복잡성들이 제거되어 구조 또한 간결해졌습니다.



#### 적어도 한 번 전송 방식

분산된 여러 네트워크 환경에서 멱등성이 중요합니다. 차선책으로 적어도 한 번 전송 방식을 사용하면 중복이 발생할 수는 있지만 누락 없는 재전송이 가능하므로 메시지 손실에 대한 걱정이 사라집니다.



#### 자연스러운 백프레셔 핸들링

카프카의 클라이언트는 pull 방식으로 동작합니다. pull 방식은 자기 자신의 속도로 데이터를 처리할 수 있습니다. 반면 푸시 방식은 브로커가 보내주는 속도에 의존해야 한다는 한계가 있습니다.



#### 강력한 파티셔닝

카프카의 파티셔닝 기능을 이용하면 논리적으로 토픽을 여러 개로 나눌 수 있습니다. 이를 통해 효과적인 수평 확장이 가능해졌습니다.



#### 그 외 여러 가지 기능

로그 컴팩션 기능을 통해 스냅샷 역할이 가능해졌고, 프로듀서와 컨슈머가 완벽하게 분리된 비동기식 방식을 사용함에 따라 애플리케이션의 병목 현상을 정확하게 파악할 수 있었고 모니터링을 통해 지연에 대한 문제를 빠르게 해결할 수 있게 됐습니다.



### 카프카로 도약의 기회를 얻은 잘란도

실시간 도메인 랭킹을 수행하는 데 카프카 기반의 Kafka Streams를 이용하기로 결정했습니다. Kafka Streams는 맵리듀스 스타일 연산에 필요한 기본 요소를 갖췄으며 실시간 처리가 가능해졌습니다.



## 1.1.2 SNS 절대 강자 트위터의 카프카 활용 사례

트위터는 대표적인 소셜 네트워크 서비스로서 사용자가 글을 적으면 그 사용자를 팔로우하는 다른 사용자들에게 메시지가 즉시 전달됩니다. 속보를 빠르게 노출해야 하고, 관련 광고를 사용자들에게 제공해야 하며, 많은 실시간 사용 사례들을 다뤄야 합니다. 트위터에서는 이러한 워크로드를 처리할 수 있는 시스템으로 그간 이벤트 버스를 구축해 운영했지만, 향후 카프카로 전환하게 됩니다.



### 카프카로 유턴한 트위터

트위터는 인하우스 메시지 시스템(이벤트 버스)을 구축했습니다. 카프카가 성장하며 트위터는 비용 절감과 커뮤니터 두 가지 측면으로 전환을 고려하게 됩니다.



#### 비용 절감 효과

성능적인 측면에서 메시지가 처리되는 양과 관계없이 이벤트 버스에 비해 카프카의 응답 속도가 빠르다는 사실을 발견합니다. 

카프카는 BPS와 상관없이 지연이 거의 발생하지 않음을 알 수 있습니다. 이러한 성능 차이를 보이는 이유로, 이벤트 버스는 서빙 레이어와 스토리지 레이어가 분리되어 있어 추가적인 홉이 필요하지만 카프카는 하나의 프로세스로 스토리지와 요청을 모두 처리한다는 차이가 있습니다. 또한 이벤트 버스는 fsync()를 하는 동안 블로킹을 하는 반면, 카프카는 OS에 의존해 백그라운드로 fsync()를 처리하고 제로카피를 사용했습니다. 결과적으로 이벤트 버스를 운영하려면 더 많은 하드웨어를 필요로 하는 반면에 카프카는 이벤트 버스만큼의 많은 하드웨어가 필요하지 않았습니다. 결국 카프카 도입을 결정함으로써 60-70%의 리소스 절감 효과를 누리게 되었습니다.



#### 강력한 커뮤니티

카프카는 이미 많은 기업에서 채택하여 사용중인 오픈소스 프로젝트입니다. 이미 다양한 사용자들의 경험이 공유되어 있어 해결 방법을 빠르게 찾기도 쉽고 데이터 엔지니어를 고용하기도 쉽습니다.



### 세계 유수 기업이 선택하는 카프카

아래와 같은 고민을 하고 있다면 카프카를 도입해 상당히 많은 문제를 해결할 수 있습니다.

* 동기/비동기 데이터 전송에 대한 고민이 있는가?
* 실시간 데이터 처리에 대한 고민이 있는가?
* 현재의 데이터 처리에 한계를 느끼는가?
* 새로운 데이터 파이프라인이 복잡하다고 느끼는가?
* 데이터 처리의 비용 절감을 고려하고 있는가?



# 1.2 국내외 카프카 이용 현황

### 해외 카프카 이용 현황

컨플루언트는 카프카 프로젝트를 리딩하고 있습니다.

라인 내부의 50여 개 서비스들이 카프카를 이용하고 있으며, 하루에만도 2,500억 건이 넘는 메시지를 처리하고 약 210TB의 데이터가 카프카로 인입된다고 합니다.

이 외에도 2020년 기준 포춘 100대 기업 중 약 80% 이상이 카프카를 사용하고 있습니다.



### 국내 카프카 이용 현황

2018년 당시 카카오는 총 7개의 클러스터를 보유하고 있고, 하루 2,600억 개의 메시지를 처리하며, 하루 약 240TB의 데이터가 카프카로 유입된다고 밝혔습니다.



# 1.3 카프카의 주요 특징

### 높은 처리량과 낮은 지연시간

카프카는 매우 높은 처리량과 낮은 지연시간을 자랑합니다. 



### 높은 확장성

링크드인에서는 카프카를 확장 가능하도록 초기부터 설계했습니다.



### 고가용성

2013년에 클러스터 내 리플리케이션 기능을 추가했고 이를 통해 카프카 클러스터의 고가용성이 확보됐습니다.



### 내구성

프로듀서는 카프카로 메시지를 전송할 때, 프로듀서의 acks라는 옵션을 조정하여 메시지의 내구성을 강화할 수 있습니다. 강력한 메시지의 내구성을 원한다면 옵션을 acks=all로 사용할 수 있습니다. 이렇게 프로듀서에 의해 카프카로 전송되는 모든 메시지는 안전한 저장소인 카프카의 로컬 디스크에 저장됩니다. 전통적인 메시지 시스템의 경우, 컨슈머가 메시지를 가져감과 동시에 저장소에서 메시지가 삭제됩니다. 반면 카프카의 경우에는 컨슈머가 메시지를 가져가더라도 메시지는 삭제되지 않고 지정된 설정 시간 또는 로그의 크기만큼 로컬 디스크에 보관하므로, 코드의 버그나 장애가 발생하더라도 과거의 메시지들을 불러와 재처리할 수 있습니다. 메시지들은 브로커 한 대에만 저장되는 것이 아니라 여러 대에 브로커에 저장하므로 브로커 중 한 대가 종료되더라도 다른 브로커의 로컬 디스크에 저장된 내용을 바탕으로 복구할 수 있습니다. 



### 개발 편의성

카프카는 메시지를 전송하는 역할을 하는 프로듀서와 메시지를 가져오는 역할을 하는 컨슈머가 완벽하게 분리되어 동작하고 서로 영향을 주지도 받지도 않습니다. 

또한 개발 편의성을 제공하기 위해 카프카에서는 카프카 커넥트와 스키마 레지스트리를 제공합니다. 스키마 레지스트리는 카프카를 사용하는 많은 개발자가 데이터 활용보다는 데이터를 파싱하는 데 많은 시간을 소모하는 매우 비효율적인 현실을 보완하고자 스키마를 정의해서 사용할 수 있도록 개발된 애플리케이션입니다.

카프카 커넥트는 프로듀서와 컨슈머를 따로 개발하지 않고도 카프카와 연동해 손쉽게 소스와 싱크로 데이터를 보내고 받을 수 있는 별도의 애플리케이션입니다.



### 운영 및 관리 편의성

카프카는 앞서 언급한 여러 장점에 힘입어 중앙 메인 데이터 파이프라인 역할을 하게 되는데 운영이나 관리의 편의성이 떨어진다면 그와 같은 주요 역할을 맡기기에 부담스러울 수 있습니다. 한 시스템에서 중요한 역할을 하는 애플리케이션이라면 성능 확장을 위한 증설 작업이 쉽고 간단해야 하며, 최신 버전이 릴리스되는 경우 무중단으로 버전 업그레이드도 가능해야 하고, 버전 업그레이드 작업 역시 단순해야 합니다.





# 1.4 카프카의 성장

### 리플리케이션 기능 추가(v0.8)

내부 카프카 클러스터에서 브로커의 장애가 발생해도 리플리케이션 기능으로 인해 데이터 유실 없이 안정적으로 사용할 수 있게 됐습니다. 

### 스키마 레지스트리 공개(v0.8.2)

카프카를 이용하는 사용자들이 늘어나고 규모가 커지면서 펍/섭 모델의 한계 같은 비효율적인 문제가 발생한다는 사실을 깨닫게 됐습니다. 카프카의 데이터 흐름은 대부분 브로드캐스트 방식이라 컨슈머 입장에서는 데이터를 전송하는 프로듀서를 일방적으로 신뢰할 수 밖에 없는 구조입니다. 이러한 구조로 인해 카프카를 사용하는 데이터 과학자나 데이터 분석가 같은 고급 인력이 데이터를 분석하거나 특히 비정형 데이터를 파싱하는 데 많은 시간을 소모하고 있었기에 이런 문제를 해결하고자 프로듀서와 컨슈머 간에 서로 데이터 구조를 설명할 수 있는 스키마를 등록 지정해 사용하는 스키마 레지스트리가 등장했습니다. 이 스키마 레지스트리를 이용해 스키마를 등록할 수 있고 이를 통해 스키마에 정의된 데이터만 주고받게 됩니다.



### 카프카 커넥트 공개(v0.9)

카프카를 사용하려면 카프카 클라이언트인 프로듀서 API, 컨슈머 API 등을 이용해야 합니다. 카프카와 연동해야하는 서비스들이 점점 늘어나며 하나하나 연동하는 클라이언트를 개발하고 유지보수하는 일은 점점 과중해지고 있습니다. 카프카 커넥트를 이용해 별도의 코드 작성 없이도 다양한 프로토콜과 카프카를 연동할 수 있게 됐습니다.



### 카프카 스트림즈 공개(v0.10)

간단하고 가벼운 카프카 스트림즈를 이용해 많은 개발자나 기업에서의 실시간 분석 처리 등이 가능해졌습니다.



### KSQL 공개

개발자들의 별도의 코드를 작성하지 않고도 익숙한 언어인 SQL 기반으로 실시간 처리 가능한 KSQL이 공개되었습니다. 이를 통해 스트림 처리 뿐만 아니라 배치 처리도 가능하며 개발자 대다수에게 익숙한 SQL 언어로 처리할 수 있다는 점은 더욱 큰 장점이었습니다. 



### 주키퍼 의존성에서 해방(v3.0)

카프카의 토픽, 브로커 등을 관리하는 목적으로 분산 코디네이터 시스템인 주키퍼를 사용해왔으나 주키퍼는 그간 카프카가 높은 성능을 갖는 데 장벽이 되어왔습니다. 2021년 9월 21일 아파치 카프카 3.0이 릴리스되어 주키퍼 의존성이 제거되었지만 아직 실제 운영 환경에서 사용하는 것은 추천하지 않습니다.



# 1.5 다양한 카프카 사용 사례

많은 기업에서는 이제 카프카를 펍/섭 모델로만 활용하는데 그치지 않고 데이터 통합, 메시지 버스, 실시간 데이터 처리, 실시간 데이터 분석 등 여러 용도로 카프카와 카프카 커넥트, 스키마 레지스트리 등을 활용하고 있습니다.



### 데이터 파이프라인: 넷플릭스 사례

전 세계에 걸쳐 커다란 규모로 데이터를 수집, 통계, 처리, 적재하기 위해 파이프라인들이 연결되어 있어 이러한 파이프라인들이 연결되어 있어 이러한 파이프라인을 연결해주는 역할로 카프카를 사용하고 있습니다.

사용자의 넷플릭스 비디오 시청 활동, 유저 인터페이스 사용 빈도, 에러 로그 등의 모든 이벤트는 데이터 파이프라인을 통해 흐르므로 넷플릭스는 이런 내용을 분석해 사용자의 경험을 예측해 능동적으로 대응할 수 있으며 오류 발생 시에도 실시간으로 대응이 가능합니다.



### 데이터 통합: 우버 사례

카프카를 사용하기 전, 데이터 엔지니어는 하나의 데이터 파이프라인을 추가할 때마다 이기종 간의 호환성 확인, 데이터 정합성 등으로 인해 매우 고단하고 번거로운 작업을 수행해야 했습니다. 하지만 카프카를 도입한 이후부터는 안정적이고 손쉽게 데이터 파이프라인 추가가 가능해졌습니다.



### 머신러닝 분야 활용 사례

컨플루언트에서 공개한 머신러닝 분야에서의 카프카 사용 사례를 보면, 데이터 전송과 파이프라인을 위해 카프카 커넥트를, 그리고 모델 생성 또는 사용 머신러닝 앱의 실시간 처리를 위해 카프카 스트림즈를 사용하고 있습니다. 그 외에도 스키마 정의를 위한 스키마 레지스트리, SQL 기반 쿼리를 위한 KSQL 등 카프카의 연계 시스템들이 종합적으로 활용되고 있습니다.



### 스마트 시티 분야 활용 사례

스마트 시티에서 데이터를 수집, 분석, 활용하는데 스마트 시티를 사용합니다. 이는 도시 규모로 발생되는 모든 데이터를 수집하고 분석합니다. 이 많은 데이터를 처리하기 위해 카프카가 필수적입니다. 여러 도시에서 수집된 데이터를 분석하려면 중앙에 위치한 카프카로 모든 데이터를 전송하게 됩니다. 이 때 카프카와 카프카 사이의 안정적인 데이터 전송을 위해서는 카프카 커넥트가 활용되며, 사전에 정의된 스키마를 이용해 데이터 변화 등에 유연하게 대응하기 위해서는 스키마 레지스트리 등이 활용됩니다.